import scrapy
from scrapy.linkextractors import LinkExtractor
from scanner_project.items import ScannedItem

class SiteSpider(scrapy.Spider):
    name = 'site_spider'

    def __init__(self, start_url=None, *args, **kwargs):
        super(SiteSpider, self).__init__(*args, **kwargs)
        if start_url:
            self.start_urls = [start_url]
            self.allowed_domains = [start_url.split('/')[2].split(':')[0]]
        else:
            raise ValueError("Se necesita un `start_url` para iniciar el escaneo.")

    def parse(self, response):
        item = ScannedItem()
        item['url'] = response.url
        item['response_headers'] = response.headers
        item['response_body'] = response.body
        item['response_status'] = response.status
        yield item

        link_extractor = LinkExtractor(allow_domains=self.allowed_domains)
        for link in link_extractor.extract_links(response):
            yield scrapy.Request(link.url, callback=self.parse)
